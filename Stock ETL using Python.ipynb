{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|hello|\n",
      "+-----+\n",
      "|spark|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"select 'spark' as hello\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, DateType, DecimalType , IntegerType, StringType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"batch pipelines\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_file = \"C:\\data\\*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"symbol\", StringType()),\n",
    "    StructField(\"date\", DateType()),\n",
    "    StructField(\"open\", DecimalType(precision=38, scale=2)),\n",
    "    StructField(\"high\", DecimalType(precision=38, scale=2)),\n",
    "    StructField(\"low\", DecimalType(precision=38, scale=2)),\n",
    "    StructField(\"close\", DecimalType(precision=38, scale=2)),\n",
    "    StructField(\"volume\", IntegerType()),\n",
    "    StructField(\"adj_close\", DecimalType(precision=38, scale=2))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(source_data_file, schema=schema).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----+-----+-----+-----+------+---------+\n",
      "|symbol|      date| open| high|  low|close|volume|adj_close|\n",
      "+------+----------+-----+-----+-----+-----+------+---------+\n",
      "|  null|      null| null| null| null| null|  null|     null|\n",
      "|    IF|2016-12-16| 6.32| 6.36| 6.23| 6.31| 11100|     6.31|\n",
      "|    IF|2016-12-15| 6.40| 6.41| 6.36| 6.40|  8500|     6.40|\n",
      "|   ISL|2016-12-16|16.08|16.08|16.08|16.08|   500|    16.08|\n",
      "|   ISL|2016-12-15|16.44|16.44|16.20|16.22|  6100|    16.22|\n",
      "|   FCO|2016-12-16| 7.96| 8.01| 7.96| 7.99| 15600|     7.99|\n",
      "|   FCO|2016-12-15| 8.03| 8.06| 8.01| 8.02| 21400|     8.02|\n",
      "|   ACU|2016-12-16|23.11|23.80|23.11|23.80|  2800|    23.80|\n",
      "|   ACU|2016-12-15|22.56|23.10|22.50|23.01|  5100|    23.01|\n",
      "|   FAX|2016-12-16| 4.75| 4.76| 4.73| 4.74|700800|     4.74|\n",
      "|   FAX|2016-12-15| 4.81| 4.81| 4.78| 4.78|625100|     4.78|\n",
      "|  AIII|2016-12-16| 1.24| 1.28| 1.02| 1.07| 83400|     1.07|\n",
      "|  AIII|2016-12-15| 1.27| 1.27| 1.15| 1.18| 11500|     1.18|\n",
      "|   IAF|2016-12-16| 5.56| 5.61| 5.55| 5.59| 49900|     5.59|\n",
      "|   IAF|2016-12-15| 5.61| 5.61| 5.55| 5.58| 91300|     5.58|\n",
      "|  ATNM|2016-12-16| 1.02| 1.02| 0.97| 1.00|145100|     1.00|\n",
      "|  ATNM|2016-12-15| 0.99| 1.02| 0.97| 1.00|161900|     1.00|\n",
      "|    AE|2016-12-16|40.80|40.99|39.01|40.98| 16900|    40.98|\n",
      "|    AE|2016-12-15|40.75|41.17|40.21|40.49|  4400|    40.49|\n",
      "|    CH|2016-12-16| 6.17| 6.21| 6.14| 6.17| 18000|     6.17|\n",
      "+------+----------+-----+-----+-----+-----+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points from files count: 2966121\n"
     ]
    }
   ],
   "source": [
    "print(\"Data points from files count: {}\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_month(date):\n",
    "    if date is not None:\n",
    "        return int(date.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(date):\n",
    "    if date is not None:\n",
    "        return int(date.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_day(date):\n",
    "    if date is not None:\n",
    "        return int(date.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_month = udf(extract_month, IntegerType())\n",
    "udf_year = udf(extract_year, IntegerType())\n",
    "udf_day = udf(extract_day, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tup = (\"close\", \"adj_close\")\n",
    "df_with_month_year = data \\\n",
    "    .withColumn(\"month\", udf_month(\"date\")) \\\n",
    "    .withColumn(\"year\", udf_year(\"date\")) \\\n",
    "    .withColumn(\"day\", udf_day(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----+-----+-----+-----+------+---------+-----+----+----+\n",
      "|symbol|      date| open| high|  low|close|volume|adj_close|month|year| day|\n",
      "+------+----------+-----+-----+-----+-----+------+---------+-----+----+----+\n",
      "|  null|      null| null| null| null| null|  null|     null| null|null|null|\n",
      "|    IF|2016-12-16| 6.32| 6.36| 6.23| 6.31| 11100|     6.31|   12|2016|  16|\n",
      "|    IF|2016-12-15| 6.40| 6.41| 6.36| 6.40|  8500|     6.40|   12|2016|  15|\n",
      "|   ISL|2016-12-16|16.08|16.08|16.08|16.08|   500|    16.08|   12|2016|  16|\n",
      "|   ISL|2016-12-15|16.44|16.44|16.20|16.22|  6100|    16.22|   12|2016|  15|\n",
      "|   FCO|2016-12-16| 7.96| 8.01| 7.96| 7.99| 15600|     7.99|   12|2016|  16|\n",
      "|   FCO|2016-12-15| 8.03| 8.06| 8.01| 8.02| 21400|     8.02|   12|2016|  15|\n",
      "|   ACU|2016-12-16|23.11|23.80|23.11|23.80|  2800|    23.80|   12|2016|  16|\n",
      "|   ACU|2016-12-15|22.56|23.10|22.50|23.01|  5100|    23.01|   12|2016|  15|\n",
      "|   FAX|2016-12-16| 4.75| 4.76| 4.73| 4.74|700800|     4.74|   12|2016|  16|\n",
      "|   FAX|2016-12-15| 4.81| 4.81| 4.78| 4.78|625100|     4.78|   12|2016|  15|\n",
      "|  AIII|2016-12-16| 1.24| 1.28| 1.02| 1.07| 83400|     1.07|   12|2016|  16|\n",
      "|  AIII|2016-12-15| 1.27| 1.27| 1.15| 1.18| 11500|     1.18|   12|2016|  15|\n",
      "|   IAF|2016-12-16| 5.56| 5.61| 5.55| 5.59| 49900|     5.59|   12|2016|  16|\n",
      "|   IAF|2016-12-15| 5.61| 5.61| 5.55| 5.58| 91300|     5.58|   12|2016|  15|\n",
      "|  ATNM|2016-12-16| 1.02| 1.02| 0.97| 1.00|145100|     1.00|   12|2016|  16|\n",
      "|  ATNM|2016-12-15| 0.99| 1.02| 0.97| 1.00|161900|     1.00|   12|2016|  15|\n",
      "|    AE|2016-12-16|40.80|40.99|39.01|40.98| 16900|    40.98|   12|2016|  16|\n",
      "|    AE|2016-12-15|40.75|41.17|40.21|40.49|  4400|    40.49|   12|2016|  15|\n",
      "|    CH|2016-12-16| 6.17| 6.21| 6.14| 6.17| 18000|     6.17|   12|2016|  16|\n",
      "+------+----------+-----+-----+-----+-----+------+---------+-----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_month_year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_month_year_count = df_with_month_year.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points after adding month, year, day: 2966121\n"
     ]
    }
   ],
   "source": [
    "print(\"Data points after adding month, year, day: {}\".format(df_with_month_year_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_with_month_year.filter(\"symbol is not NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----+-----+-----+-----+------+---------+-----+----+---+\n",
      "|symbol|      date| open| high|  low|close|volume|adj_close|month|year|day|\n",
      "+------+----------+-----+-----+-----+-----+------+---------+-----+----+---+\n",
      "|    IF|2016-12-16| 6.32| 6.36| 6.23| 6.31| 11100|     6.31|   12|2016| 16|\n",
      "|    IF|2016-12-15| 6.40| 6.41| 6.36| 6.40|  8500|     6.40|   12|2016| 15|\n",
      "|   ISL|2016-12-16|16.08|16.08|16.08|16.08|   500|    16.08|   12|2016| 16|\n",
      "|   ISL|2016-12-15|16.44|16.44|16.20|16.22|  6100|    16.22|   12|2016| 15|\n",
      "|   FCO|2016-12-16| 7.96| 8.01| 7.96| 7.99| 15600|     7.99|   12|2016| 16|\n",
      "|   FCO|2016-12-15| 8.03| 8.06| 8.01| 8.02| 21400|     8.02|   12|2016| 15|\n",
      "|   ACU|2016-12-16|23.11|23.80|23.11|23.80|  2800|    23.80|   12|2016| 16|\n",
      "|   ACU|2016-12-15|22.56|23.10|22.50|23.01|  5100|    23.01|   12|2016| 15|\n",
      "|   FAX|2016-12-16| 4.75| 4.76| 4.73| 4.74|700800|     4.74|   12|2016| 16|\n",
      "|   FAX|2016-12-15| 4.81| 4.81| 4.78| 4.78|625100|     4.78|   12|2016| 15|\n",
      "|  AIII|2016-12-16| 1.24| 1.28| 1.02| 1.07| 83400|     1.07|   12|2016| 16|\n",
      "|  AIII|2016-12-15| 1.27| 1.27| 1.15| 1.18| 11500|     1.18|   12|2016| 15|\n",
      "|   IAF|2016-12-16| 5.56| 5.61| 5.55| 5.59| 49900|     5.59|   12|2016| 16|\n",
      "|   IAF|2016-12-15| 5.61| 5.61| 5.55| 5.58| 91300|     5.58|   12|2016| 15|\n",
      "|  ATNM|2016-12-16| 1.02| 1.02| 0.97| 1.00|145100|     1.00|   12|2016| 16|\n",
      "|  ATNM|2016-12-15| 0.99| 1.02| 0.97| 1.00|161900|     1.00|   12|2016| 15|\n",
      "|    AE|2016-12-16|40.80|40.99|39.01|40.98| 16900|    40.98|   12|2016| 16|\n",
      "|    AE|2016-12-15|40.75|41.17|40.21|40.49|  4400|    40.49|   12|2016| 15|\n",
      "|    CH|2016-12-16| 6.17| 6.21| 6.14| 6.17| 18000|     6.17|   12|2016| 16|\n",
      "|    CH|2016-12-15| 6.28| 6.28| 6.17| 6.22| 32500|     6.22|   12|2016| 15|\n",
      "+------+----------+-----+-----+-----+-----+------+---------+-----+----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points remaining after removing nulls: 2965870\n"
     ]
    }
   ],
   "source": [
    "df2_count = df2.count()\n",
    "print(\"Data points remaining after removing nulls: {}\".format(df2_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 251 nulls\n"
     ]
    }
   ],
   "source": [
    "print(\"Removed {} nulls\".format(df_with_month_year_count - df2_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------------------+\n",
      "|month|year|average_month_close|\n",
      "+-----+----+-------------------+\n",
      "|   12|2015|          28.854235|\n",
      "|    1|2016|          26.868989|\n",
      "|    2|2016|          26.402522|\n",
      "|    3|2016|          28.388157|\n",
      "|    4|2016|          29.081379|\n",
      "|    5|2016|          29.032151|\n",
      "|    6|2016|          29.484503|\n",
      "|    7|2016|          30.366564|\n",
      "|    8|2016|          33.058425|\n",
      "|    9|2016|          35.427533|\n",
      "|   10|2016|          35.053195|\n",
      "|   11|2016|          35.915486|\n",
      "|   12|2016|          43.785477|\n",
      "+-----+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "monthly_avg_close_df = df2.groupBy(df2.month,df2.year).agg(avg(\"close\").alias(\"average_month_close\")).orderBy(df2.year,df2.month)\n",
    "\n",
    "monthly_avg_close_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "|month|year|count|\n",
      "+-----+----+-----+\n",
      "|   12|2015|   34|\n",
      "|    1|2016|  835|\n",
      "|    2|2016| 1353|\n",
      "|    3|2016| 1390|\n",
      "|    4|2016|  920|\n",
      "|    5|2016| 1490|\n",
      "|    6|2016| 1495|\n",
      "|    7|2016|  925|\n",
      "|    8|2016| 1445|\n",
      "|    9|2016| 1285|\n",
      "|   10|2016|  906|\n",
      "|   11|2016| 1366|\n",
      "|   12|2016| 1514|\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adj_close_diff_than_close = df2.filter(\"close != adj_close\").groupBy(df2.month,df2.year).count().orderBy(df2.year,df2.month)\n",
    "\n",
    "adj_close_diff_than_close.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = df2.filter(\"close != adj_close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StructType, StructField, DateType, DecimalType , IntegerType, StringType\n",
    "def finclose(close,adj_close):\n",
    "    if close == adj_close:\n",
    "        return close\n",
    "    elif close > adj_close:\n",
    "        return close\n",
    "    else:\n",
    "        return adj_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tup = (\"close\", \"adj_close\")\n",
    "udf_finalclose = udf(finclose, DecimalType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_month_year = data.withColumn('fin_close', udf_finalclose('close','adj_close')) \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----+-----+-----+-----+------+---------+---------+\n",
      "|symbol|      date| open| high|  low|close|volume|adj_close|fin_close|\n",
      "+------+----------+-----+-----+-----+-----+------+---------+---------+\n",
      "|  null|      null| null| null| null| null|  null|     null|     null|\n",
      "|    IF|2016-12-16| 6.32| 6.36| 6.23| 6.31| 11100|     6.31|        6|\n",
      "|    IF|2016-12-15| 6.40| 6.41| 6.36| 6.40|  8500|     6.40|        6|\n",
      "|   ISL|2016-12-16|16.08|16.08|16.08|16.08|   500|    16.08|       16|\n",
      "|   ISL|2016-12-15|16.44|16.44|16.20|16.22|  6100|    16.22|       16|\n",
      "|   FCO|2016-12-16| 7.96| 8.01| 7.96| 7.99| 15600|     7.99|        8|\n",
      "|   FCO|2016-12-15| 8.03| 8.06| 8.01| 8.02| 21400|     8.02|        8|\n",
      "|   ACU|2016-12-16|23.11|23.80|23.11|23.80|  2800|    23.80|       24|\n",
      "|   ACU|2016-12-15|22.56|23.10|22.50|23.01|  5100|    23.01|       23|\n",
      "|   FAX|2016-12-16| 4.75| 4.76| 4.73| 4.74|700800|     4.74|        5|\n",
      "|   FAX|2016-12-15| 4.81| 4.81| 4.78| 4.78|625100|     4.78|        5|\n",
      "|  AIII|2016-12-16| 1.24| 1.28| 1.02| 1.07| 83400|     1.07|        1|\n",
      "|  AIII|2016-12-15| 1.27| 1.27| 1.15| 1.18| 11500|     1.18|        1|\n",
      "|   IAF|2016-12-16| 5.56| 5.61| 5.55| 5.59| 49900|     5.59|        6|\n",
      "|   IAF|2016-12-15| 5.61| 5.61| 5.55| 5.58| 91300|     5.58|        6|\n",
      "|  ATNM|2016-12-16| 1.02| 1.02| 0.97| 1.00|145100|     1.00|        1|\n",
      "|  ATNM|2016-12-15| 0.99| 1.02| 0.97| 1.00|161900|     1.00|        1|\n",
      "|    AE|2016-12-16|40.80|40.99|39.01|40.98| 16900|    40.98|       41|\n",
      "|    AE|2016-12-15|40.75|41.17|40.21|40.49|  4400|    40.49|       40|\n",
      "|    CH|2016-12-16| 6.17| 6.21| 6.14| 6.17| 18000|     6.17|        6|\n",
      "+------+----------+-----+-----+-----+-----+------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_month_year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
